name: caption_generation
description: "Generate natural language captions from images/video using vision-language models (BLIP, BLIP-2, ViT-GPT2, LLaVA) for accessibility and content understanding"

inputs:
  - jpg
  - jpeg
  - png
  - bmp
  - webp
  - dpx
  - Keyframes

outputs:
  - CaptionGeneration

config:
  max_file_size_mb: 100
  requires_gpu: false
  experimental: true

performance:
  avg_processing_time_per_gb: "60s"
  memory_per_file_mb: 512
  supports_streaming: false

cache:
  enabled: true
  version: 1
  invalidate_before: 1730419200  # 2024-11-01 00:00:00 UTC

# Implementation location
implementation:
  crate: "video-audio-caption-generation"
  function: "generate_caption"
