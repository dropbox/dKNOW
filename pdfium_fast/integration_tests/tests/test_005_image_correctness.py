"""
Image Correctness Test - All 196 Benchmark PDFs

Validates 1-worker image rendering correctness against upstream PDFium baselines.

All PDFs must match 100% (byte-for-byte identical PPM MD5 hashes).

Uses pdfium_cli (C++ CLI with proper form rendering) which matches upstream pdfium_test.

HISTORICAL NOTE (2025-11-04):
  Before WORKER1 # 1, pdfium_cli was missing FPDF_FFLDraw() which caused forms to render
  as white/invisible. This affected 9 PDFs:
    - 0100pages_7FKQLKX273JBHXAAW5XDRT27JGMIZMCI (0.86% pixels, page 10 form field)
    - 0130pages_ZJJJ6P4UAGH7LKLACPT5P437FB5F3MYF (0.03% pixels, imperceptible)
    - 0309pages_7LD3RVJDZGTXF53CDLCI67YPWZQ5POOA (0.04% pixels, 2 checkboxes)
    - 0496pages_E3474JUEVRWQ3P2J2I3XBFKMMVZLLKWZ (0.04% pixels)
    - 1931pages_7ZNNFJGHOEFFP6I4OARCZGH3GPPDNDXC (0.01% pixels, page 1000)
    - cc_013_122p (0.24% pixels, page 66)
    - web_003 (28.77% pixels, page 4, large web form)
    - web_026 (15.55% pixels, page 2, web form)
    - web_041 (44.47% pixels, page 0, entire page was form!)

  All now fixed - these PDFs render 100% correctly and match upstream perfectly.

META:
  id: image_correctness
  category: correctness
  level: extended
  type: image
  pdf_count: 196
  duration: 1h
  workers: 1

RUN: pytest -m 'extended and image'
"""

import pytest
from pathlib import Path


def get_all_benchmark_pdfs():
    """Get all 196 PDFs from testing/pdfs/benchmark/."""
    pdf_dir = Path(__file__).parent.parent / 'pdfs' / 'benchmark'
    return sorted([p.name for p in pdf_dir.glob('*.pdf')])


def pytest_generate_tests(metafunc):
    """Parametrize with all benchmark PDFs."""
    if "pdf_name" in metafunc.fixturenames:
        single_pdf = metafunc.config.getoption("--pdf")
        if single_pdf:
            pdfs = [single_pdf]
        else:
            pdfs = get_all_benchmark_pdfs()

        metafunc.parametrize("pdf_name", pdfs, ids=lambda p: Path(p).stem[:50])


@pytest.mark.corpus
@pytest.mark.correctness
@pytest.mark.image
def test_image_rendering_correctness(
    pdf_name,
    benchmark_pdfs,
    optimized_lib,
    render_tool,
    baseline_manager,
    request
):
    """
    Test single-worker image rendering - 100% correctness required.

    N=352: Added disk space management to prevent false failures.
    PPM format requires ~25MB per page. Large PDFs skipped in automated suite
    to prevent disk exhaustion (which caused "flaky test" false positives in N=342-351).

    META:
      id: image_correctness_001
      category: correctness
      level: extended
      type: image
      pdf_count: 196
      duration: 1h
      workers: [1]
      validates: Image rendering produces byte-for-byte identical output
      impact: critical

    DESCRIPTION:
      Validates that image rendering (1 worker) produces output matching
      upstream PDFium baselines (100% MD5 match required).

      Uses pdfium_cli (C++ CLI) with proper form rendering via FPDF_FFLDraw.
      Forms now render correctly, matching upstream pdfium_test.

      Uses MD5 hash comparison for each page (PPM format).

    SUCCESS:
      - All pages match 100% (0 mismatches)

    FAILURE:
      - Any MD5 mismatch indicates rendering bug
    """
    pdf_path = benchmark_pdfs / pdf_name

    if not pdf_path.exists():
        pytest.skip(f"PDF not found: {pdf_name}")

    # Load upstream baseline (MD5 hashes per page)
    upstream_hashes = baseline_manager.load_image_baseline(pdf_name)
    if not upstream_hashes:
        pytest.skip(f"Image baseline not generated for {pdf_name}")

    # Get PDF metadata
    pdf_size_mb = pdf_path.stat().st_size / (1024**2)
    page_count = len(upstream_hashes)

    # N=352: Disk space pre-check to prevent mid-test failures
    # PPM format: ~25MB per page, need 20% safety margin
    required_gb = (page_count * 25) / 1024 * 1.2
    import shutil
    free_gb = shutil.disk_usage('/tmp').free / (1024**3)

    if free_gb < required_gb:
        pytest.skip(f"Insufficient disk space: {free_gb:.1f}GB free, need {required_gb:.1f}GB for {page_count} pages PPM")

    # Note: render_with_md5() deletes PPM files immediately after MD5 computation
    # This batched processing limits disk usage to ~300MB regardless of PDF size
    # (See conftest.py:render_with_md5 line 719 for cleanup implementation)

    # Render with 1 worker to match upstream pdfium_test (single-threaded)
    # Baselines generated by: out/Optimized-Shared/pdfium_test --ppm --scale=4.166666
    # NOTE: Multi-process is disabled for correctness (see TASK 2 in render_pages.rs)
    import time
    start = time.time()
    actual_hashes = pytest.render_with_md5(pdf_path, 1, optimized_lib, render_tool)
    duration = time.time() - start

    assert actual_hashes is not None, f"Rendering failed for {pdf_name}"
    assert len(actual_hashes) > 0, "No pages rendered"

    # Telemetry
    request.node._report_pdf_name = pdf_name
    request.node._report_pdf_pages = len(actual_hashes)
    request.node._report_pdf_size_mb = round(pdf_size_mb, 2)
    request.node._report_worker_count = 1
    request.node._report_total_pages = len(actual_hashes)
    request.node._report_total_time_sec = duration
    request.node._report_pages_per_sec = len(actual_hashes) / duration if duration > 0 else 0

    # Validate MD5 hashes - compare each page
    # Require 100% match (0% mismatch)
    mismatches = []
    for page_num, expected_md5 in upstream_hashes.items():
        actual_md5 = actual_hashes.get(page_num)
        if actual_md5 is None:
            mismatches.append(f"Page {page_num}: missing in actual output")
        elif actual_md5 != expected_md5:
            mismatches.append(f"Page {page_num}: expected {expected_md5}, got {actual_md5}")

    # Check for extra pages in actual output
    for page_num in actual_hashes:
        if page_num not in upstream_hashes:
            mismatches.append(f"Page {page_num}: unexpected page in actual output")

    # Fail if ANY mismatch (100% correctness required)
    if mismatches:
        assert False, (
            f"MD5 mismatch detected: {len(mismatches)}/{len(upstream_hashes)} pages\n"
            f"PDF: {pdf_name}\n"
            f"\n"
            f"Mismatches (showing first 10):\n" +
            "\n".join(f"  {mm}" for mm in mismatches[:10]) +
            f"\n\nAll pages must match 100% (byte-for-byte identical PPM MD5 hashes with upstream baseline)."
        )
