// examples/world_class_multilingual.rs
//
// Demonstrates world-class multilingual support:
// English, Japanese, Chinese, Korean, Arabic, and mixed content

use markdown_chunker::Chunker;

fn main() {
    println!("ğŸŒ World-Class Multilingual Markdown Chunker Demo\n");
    println!("{}", "=".repeat(60));

    // English
    let english = r"
# English Document

This is a sample document in English. The chunker handles English text
with approximately 4 characters per token estimation.

## Features

- Markdown structure preservation
- Code block protection
- Smart sentence boundaries
";

    // Japanese
    let japanese = r"
# æ—¥æœ¬èªã®æ–‡æ›¸

ã“ã‚Œã¯æ—¥æœ¬èªã®ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸ã§ã™ã€‚ãƒãƒ£ãƒ³ã‚«ãƒ¼ã¯æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«å‡¦ç†ã—ã¾ã™ã€‚
ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã®ã™ã¹ã¦ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

## ç‰¹å¾´

- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³æ§‹é€ ã®ä¿æŒ
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ä¿è­·
- æ–‡ã®å¢ƒç•Œã®èªè­˜
";

    // Chinese
    let chinese = r"
# ä¸­æ–‡æ–‡æ¡£

è¿™æ˜¯ä¸€ä¸ªä¸­æ–‡ç¤ºä¾‹æ–‡æ¡£ã€‚åˆ†å—å™¨å¯ä»¥æ­£ç¡®å¤„ç†ä¸­æ–‡æ–‡æœ¬ã€‚
æ”¯æŒç®€ä½“å’Œç¹ä½“ä¸­æ–‡ã€‚

## ç‰¹ç‚¹

- ä¿ç•™Markdownç»“æ„
- ä¿æŠ¤ä»£ç å—
- æ™ºèƒ½å¥å­è¾¹ç•Œ
";

    // Arabic
    let arabic = r"
# ÙˆØ«ÙŠÙ‚Ø© Ø¹Ø±Ø¨ÙŠØ©

Ù‡Ø°Ø§ Ù…Ø³ØªÙ†Ø¯ Ø¹Ø±Ø¨ÙŠ Ù†Ù…ÙˆØ°Ø¬ÙŠ. ÙŠØªØ¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø¬Ø²Ø¦ Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.
ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

## Ø§Ù„Ù…ÙŠØ²Ø§Øª

- Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© Markdown
- Ø­Ù…Ø§ÙŠØ© ÙƒØªÙ„ Ø§Ù„ÙƒÙˆØ¯
- Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø°ÙƒÙŠØ©
";

    // Mixed content (English + Japanese)
    let mixed = r"
# Multilingual Document / å¤šè¨€èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

This document contains both English and Japanese text.
ã“ã®æ–‡æ›¸ã«ã¯è‹±èªã¨æ—¥æœ¬èªã®ä¸¡æ–¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## Technical Details / æŠ€è¡“è©³ç´°

The chunker uses character-based detection to identify scripts:
- CJK characters: ~2 chars per token
- Arabic characters: ~5 chars per token
- Latin characters: ~4 chars per token

æ—¥æœ¬èªã®æ–‡å­—ã¯è‡ªå‹•çš„ã«æ¤œå‡ºã•ã‚Œã€é©åˆ‡ãªãƒˆãƒ¼ã‚¯ãƒ³æ¨å®šãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚
";

    let chunker = Chunker::default();

    // Process each language
    println!("\nğŸ“ ENGLISH:");
    process_and_display(&chunker, english, "English");

    println!("\nğŸ“ JAPANESE (æ—¥æœ¬èª):");
    process_and_display(&chunker, japanese, "Japanese");

    println!("\nğŸ“ CHINESE (ä¸­æ–‡):");
    process_and_display(&chunker, chinese, "Chinese");

    println!("\nğŸ“ ARABIC (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©):");
    process_and_display(&chunker, arabic, "Arabic");

    println!("\nğŸ“ MIXED (English + æ—¥æœ¬èª):");
    process_and_display(&chunker, mixed, "Mixed");

    println!("\n{}", "=".repeat(60));
    println!("âœ… All languages processed successfully!");
    println!("ğŸŒ World-class multilingual support verified!");
}

fn process_and_display(chunker: &Chunker, text: &str, language: &str) {
    let chunks = chunker.chunk(text);

    println!("  Language: {language}");
    println!("  Chunks generated: {}", chunks.len());

    for (i, chunk) in chunks.iter().enumerate() {
        let preview = chunk
            .content
            .lines()
            .next()
            .unwrap_or("")
            .chars()
            .take(50)
            .collect::<String>();

        println!(
            "    Chunk {}: {} tokens, {} chars - \"{}...\"",
            i + 1,
            chunk.metadata.token_count,
            chunk.metadata.char_count,
            preview
        );
    }
}
