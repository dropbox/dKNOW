# LLM-as-Judge Score-Based Training Configuration
#
# Trains model to predict LLM-assigned relevance scores (1-5)
# for semantic understanding of (query, code) pairs.
#
# Usage:
#   python scripts/train_llm_judge.py --config config/train_llm_judge.yaml

data:
  # Scored training data (generated by scripts/score_relevance.py)
  train: "data/scored_training.jsonl"
  validation: "data/scored_validation.jsonl"

  # Field containing LLM relevance score (1-5)
  score_field: "llm_score"

model:
  # Start from MLX-trained model (already good at keyword matching)
  base: "checkpoints/xtr-mlx-merged"

  # Output directory for score-trained model
  output: "checkpoints/xtr-llm-judge"

training:
  # Loss function: "mse" (simple), "ordinal" (better for 1-5), "margin_weighted" (ranking)
  loss: "mse"

  # LoRA configuration
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules: ["q", "v", "k", "o", "wi_0", "wi_1", "wo"]

  # Training hyperparameters
  batch_size: 16
  gradient_accumulation_steps: 2
  epochs: 3
  learning_rate: 1.0e-5  # Lower LR for fine-tuning on scores
  max_length: 512

  # Evaluation and checkpointing
  eval_every: 300
  save_every: 500

  # Early stopping on validation correlation
  early_stopping_patience: 5
